From da0d76634e1aa30eb3738fe34e2e6721a9845411 Mon Sep 17 00:00:00 2001
From: WANG Xuerui <git@xen0n.name>
Date: Tue, 21 Mar 2023 00:46:11 +0800
Subject: [PATCH 46/48] [release-branch.go1.20] cmd/compile: wire up
 math/bits.Len intrinsics for loong64
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

For the SubFromLen64 codegen test case to work as intended, we need
to fold c-(-(x-d)) into x+(c-d).

Still, some instances of LeadingZeros are not optimized into single
CLZ instructions right now (actually, the LeadingZeros micro-benchmarks
are currently still compiled with redundant adds/subs of 64, due to
interference of loop optimizations before lowering), but perf numbers
indicate it's not that bad after all.

Micro-benchmark results on Loongson 3A5000:

goos: linux
goarch: loong64
pkg: math/bits
               │   before    │                after                │
               │   sec/op    │   sec/op     vs base                │
LeadingZeros     3.675n ± 0%   1.545n ± 1%  -57.96% (p=0.000 n=10)
LeadingZeros8    2.001n ± 0%   1.868n ± 0%   -6.62% (p=0.000 n=10)
LeadingZeros16   3.144n ± 0%   1.864n ± 1%  -40.71% (p=0.000 n=10)
LeadingZeros32   4.265n ± 1%   1.653n ± 1%  -61.24% (p=0.000 n=10)
LeadingZeros64   3.962n ± 0%   1.539n ± 0%  -61.16% (p=0.000 n=10)
geomean          3.299n        1.688n       -48.84%

go1 benchmark results on the same box:

goos: linux
goarch: loong64
pkg: test/bench/go1
                      │  CL 483355  │              this CL               │
                      │   sec/op    │   sec/op     vs base               │
BinaryTree17             13.75 ± 2%    13.70 ± 2%       ~ (p=0.579 n=10)
Fannkuch11               3.650 ± 0%    3.415 ± 0%  -6.46% (p=0.000 n=10)
FmtFprintfEmpty         94.45n ± 0%   94.98n ± 0%  +0.56% (p=0.000 n=10)
FmtFprintfString        155.2n ± 0%   151.1n ± 0%  -2.61% (p=0.000 n=10)
FmtFprintfInt           154.4n ± 0%   153.6n ± 0%  -0.52% (p=0.000 n=10)
FmtFprintfIntInt        237.1n ± 0%   234.7n ± 0%  -0.99% (p=0.000 n=10)
FmtFprintfPrefixedInt   312.8n ± 0%   314.2n ± 0%  +0.45% (p=0.000 n=10)
FmtFprintfFloat         390.5n ± 0%   402.1n ± 0%  +2.97% (p=0.000 n=10)
FmtManyArgs             905.0n ± 0%   918.6n ± 0%  +1.51% (p=0.000 n=10)
GobDecode               14.93m ± 1%   14.98m ± 1%  +0.33% (p=0.015 n=10)
GobEncode               17.33m ± 0%   17.26m ± 1%  -0.39% (p=0.023 n=10)
Gzip                    404.3m ± 0%   404.6m ± 0%  +0.08% (p=0.000 n=10)
Gunzip                  80.92m ± 0%   80.97m ± 0%  +0.06% (p=0.000 n=10)
HTTPClientServer        86.14µ ± 0%   84.39µ ± 0%  -2.03% (p=0.000 n=10)
JSONEncode              18.49m ± 0%   18.50m ± 0%       ~ (p=0.436 n=10)
JSONDecode              77.34m ± 1%   76.26m ± 1%  -1.40% (p=0.000 n=10)
Mandelbrot200           6.521m ± 0%   6.508m ± 0%       ~ (p=0.138 n=10)
GoParse                 7.324m ± 1%   7.413m ± 1%  +1.22% (p=0.005 n=10)
RegexpMatchEasy0_32     134.6n ± 0%   134.6n ± 0%       ~ (p=0.195 n=10)
RegexpMatchEasy0_1K     1.365µ ± 0%   1.366µ ± 0%  +0.07% (p=0.038 n=10)
RegexpMatchEasy1_32     164.1n ± 0%   164.1n ± 0%       ~ (p=0.230 n=10)
RegexpMatchEasy1_1K     1.492µ ± 0%   1.492µ ± 0%       ~ (p=0.211 n=10)
RegexpMatchMedium_32    1.404µ ± 0%   1.403µ ± 0%  -0.07% (p=0.000 n=10)
RegexpMatchMedium_1K    41.05µ ± 0%   41.04µ ± 0%  -0.04% (p=0.000 n=10)
RegexpMatchHard_32      2.072µ ± 0%   2.071µ ± 0%  -0.05% (p=0.000 n=10)
RegexpMatchHard_1K      60.89µ ± 0%   60.87µ ± 0%  -0.04% (p=0.000 n=10)
Revcomp                  1.199 ± 1%    1.200 ± 0%       ~ (p=0.481 n=10)
Template                112.3m ± 2%   112.9m ± 2%       ~ (p=0.353 n=10)
TimeParse               414.2n ± 1%   412.5n ± 0%  -0.40% (p=0.000 n=10)
TimeFormat              496.9n ± 0%   496.6n ± 0%       ~ (p=0.341 n=10)
geomean                 101.0µ        100.7µ       -0.26%

                     │  CL 483355   │                this CL                │
                     │     B/s      │     B/s       vs base                 │
GobDecode              49.02Mi ± 1%   48.87Mi ± 1%  -0.32% (p=0.014 n=10)
GobEncode              42.23Mi ± 0%   42.40Mi ± 1%  +0.40% (p=0.022 n=10)
Gzip                   45.77Mi ± 0%   45.73Mi ± 0%  -0.07% (p=0.000 n=10)
Gunzip                 228.7Mi ± 0%   228.6Mi ± 0%  -0.06% (p=0.000 n=10)
JSONEncode             100.1Mi ± 0%   100.0Mi ± 0%       ~ (p=0.470 n=10)
JSONDecode             23.93Mi ± 1%   24.27Mi ± 1%  +1.43% (p=0.000 n=10)
GoParse                7.544Mi ± 1%   7.448Mi ± 1%  -1.26% (p=0.005 n=10)
RegexpMatchEasy0_32    226.8Mi ± 0%   226.7Mi ± 0%  -0.06% (p=0.001 n=10)
RegexpMatchEasy0_1K    715.7Mi ± 0%   715.1Mi ± 0%  -0.08% (p=0.022 n=10)
RegexpMatchEasy1_32    186.0Mi ± 0%   186.0Mi ± 0%       ~ (p=0.493 n=10)
RegexpMatchEasy1_1K    654.3Mi ± 0%   654.6Mi ± 0%  +0.04% (p=0.000 n=10)
RegexpMatchMedium_32   21.74Mi ± 0%   21.74Mi ± 0%  +0.02% (p=0.022 n=10)
RegexpMatchMedium_1K   23.78Mi ± 0%   23.79Mi ± 0%  +0.04% (p=0.000 n=10)
RegexpMatchHard_32     14.72Mi ± 0%   14.73Mi ± 0%  +0.06% (p=0.000 n=10)
RegexpMatchHard_1K     16.04Mi ± 0%   16.04Mi ± 0%       ~ (p=1.000 n=10) ¹
Revcomp                202.2Mi ± 1%   202.0Mi ± 0%       ~ (p=0.469 n=10)
Template               16.48Mi ± 2%   16.38Mi ± 2%       ~ (p=0.342 n=10)
geomean                62.23Mi        62.21Mi       -0.04%
¹ all samples are equal

In this case though, all significant perf changes are likely due to
micro-architectural quirks.

Updates #59120

Change-Id: Icc8f7d8e79c6168aae634f5c36f044f3fd034d89
(cherry picked from commit 80a298243a07e982573e14723d8133fc5be45065)
---
 src/cmd/compile/internal/loong64/ssa.go       |  2 +
 .../compile/internal/ssa/_gen/LOONG64.rules   | 11 ++-
 .../compile/internal/ssa/_gen/LOONG64Ops.go   |  2 +
 src/cmd/compile/internal/ssa/opGen.go         | 28 ++++++
 .../compile/internal/ssa/rewriteLOONG64.go    | 91 +++++++++++++++++++
 src/cmd/compile/internal/ssagen/ssa.go        | 10 +-
 test/codegen/mathbits.go                      | 16 ++++
 7 files changed, 153 insertions(+), 7 deletions(-)

diff --git a/src/cmd/compile/internal/loong64/ssa.go b/src/cmd/compile/internal/loong64/ssa.go
index 074e5d1c2d..51d318a21d 100644
--- a/src/cmd/compile/internal/loong64/ssa.go
+++ b/src/cmd/compile/internal/loong64/ssa.go
@@ -350,6 +350,8 @@ func ssaGenValue(s *ssagen.State, v *ssa.Value) {
 		ssa.OpLOONG64NEGD,
 		ssa.OpLOONG64CTZW,
 		ssa.OpLOONG64CTZV,
+		ssa.OpLOONG64CLZW,
+		ssa.OpLOONG64CLZV,
 		ssa.OpLOONG64SQRTD,
 		ssa.OpLOONG64SQRTF:
 		p := s.Prog(v.Op.Asm())
diff --git a/src/cmd/compile/internal/ssa/_gen/LOONG64.rules b/src/cmd/compile/internal/ssa/_gen/LOONG64.rules
index 2a6607e402..960cd26eab 100644
--- a/src/cmd/compile/internal/ssa/_gen/LOONG64.rules
+++ b/src/cmd/compile/internal/ssa/_gen/LOONG64.rules
@@ -131,6 +131,8 @@
 
 (Ctz(32|64)NonZero ...) => (Ctz(32|64) ...)
 (Ctz(32|64) ...) => (CTZ(W|V) ...)
+(BitLen64 <t> x) => (NEGV <t> (SUBVconst <t> [64] (CLZV <t> x)))
+(BitLen32 <t> x) => (NEGV <t> (SUBVconst <t> [32] (CLZW <t> x)))
 
 (Sqrt ...) => (SQRTD ...)
 (Sqrt32 ...) => (SQRTF ...)
@@ -590,8 +592,12 @@
 (ROTR x (MOVVconst [c]))  => (ROTRconst x [c&31])
 (ROTRV x (MOVVconst [c])) => (ROTRVconst x [c&63])
 
-(SGT  (MOVVconst [c]) x) && is32Bit(c) => (SGTconst  [c] x)
-(SGTU (MOVVconst [c]) x) && is32Bit(c) => (SGTUconst [c] x)
+// c > d-x => x > d-c
+(SGT (MOVVconst [c]) (NEGV (SUBVconst [d] x))) && is32Bit(d-c) => (SGT x (MOVVconst [d-c]))
+
+(S(GT|GTU) (MOVVconst [c]) x) && is32Bit(c) => (S(GT|GTU)const [c] x)
+// x > c => !(x <= c) => !(x < (c+1))
+//(S(GT|GTU) x (MOVVconst [c])) && is32Bit(c+1) => (XORconst [1] (S(GT|GTU)const [c+1] x))
 
 // mul by constant
 (MULV x (MOVVconst [-1])) => (NEGV x)
@@ -664,6 +670,7 @@
 (SUBVconst [c] (MOVVconst [d]))  => (MOVVconst [d-c])
 (SUBVconst [c] (SUBVconst [d] x)) && is32Bit(-c-d) => (ADDVconst [-c-d] x)
 (SUBVconst [c] (ADDVconst [d] x)) && is32Bit(-c+d) => (ADDVconst [-c+d] x)
+(SUBV (MOVVconst [c]) (NEGV (SUBVconst [d] x))) => (ADDVconst [c-d] x)
 (SLLVconst [c] (MOVVconst [d]))  => (MOVVconst [d<<uint64(c)])
 (SRLVconst [c] (MOVVconst [d]))  => (MOVVconst [int64(uint64(d)>>uint64(c))])
 (SRAVconst [c] (MOVVconst [d]))  => (MOVVconst [d>>uint64(c)])
diff --git a/src/cmd/compile/internal/ssa/_gen/LOONG64Ops.go b/src/cmd/compile/internal/ssa/_gen/LOONG64Ops.go
index 3123c34662..c601b0d517 100644
--- a/src/cmd/compile/internal/ssa/_gen/LOONG64Ops.go
+++ b/src/cmd/compile/internal/ssa/_gen/LOONG64Ops.go
@@ -204,6 +204,8 @@ func init() {
 		{name: "SQRTF", argLength: 1, reg: fp11, asm: "SQRTF"}, // sqrt(arg0), float32
 		{name: "CTZW", argLength: 1, reg: gp11, asm: "CTZW"},   // Count trailing (low order) zeroes (returns 0-32)
 		{name: "CTZV", argLength: 1, reg: gp11, asm: "CTZV"},   // Count trailing (low order) zeroes (returns 0-64)
+		{name: "CLZW", argLength: 1, reg: gp11, asm: "CLZW"},   // Count leading (high order) zeroes (returns 0-32)
+		{name: "CLZV", argLength: 1, reg: gp11, asm: "CLZV"},   // Count leading (high order) zeroes (returns 0-64)
 
 		{name: "MASKEQZ", argLength: 2, reg: gp21, asm: "MASKEQZ"}, // returns 0 if arg1 == 0, otherwise returns arg0
 		{name: "MASKNEZ", argLength: 2, reg: gp21, asm: "MASKNEZ"}, // returns 0 if arg1 != 0, otherwise returns arg0
diff --git a/src/cmd/compile/internal/ssa/opGen.go b/src/cmd/compile/internal/ssa/opGen.go
index 40bab454a5..54748ccbe0 100644
--- a/src/cmd/compile/internal/ssa/opGen.go
+++ b/src/cmd/compile/internal/ssa/opGen.go
@@ -1753,6 +1753,8 @@ const (
 	OpLOONG64SQRTF
 	OpLOONG64CTZW
 	OpLOONG64CTZV
+	OpLOONG64CLZW
+	OpLOONG64CLZV
 	OpLOONG64MASKEQZ
 	OpLOONG64MASKNEZ
 	OpLOONG64SLLV
@@ -23478,6 +23480,32 @@ var opcodeTable = [...]opInfo{
 			},
 		},
 	},
+	{
+		name:   "CLZW",
+		argLen: 1,
+		asm:    loong64.ACLZW,
+		reg: regInfo{
+			inputs: []inputInfo{
+				{0, 1072693240}, // R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R18 R19 R20 g R23 R24 R25 R26 R27 R28 R29 R31
+			},
+			outputs: []outputInfo{
+				{0, 1070596088}, // R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R18 R19 R20 R23 R24 R25 R26 R27 R28 R29 R31
+			},
+		},
+	},
+	{
+		name:   "CLZV",
+		argLen: 1,
+		asm:    loong64.ACLZV,
+		reg: regInfo{
+			inputs: []inputInfo{
+				{0, 1072693240}, // R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R18 R19 R20 g R23 R24 R25 R26 R27 R28 R29 R31
+			},
+			outputs: []outputInfo{
+				{0, 1070596088}, // R4 R5 R6 R7 R8 R9 R10 R11 R12 R13 R14 R15 R16 R17 R18 R19 R20 R23 R24 R25 R26 R27 R28 R29 R31
+			},
+		},
+	},
 	{
 		name:   "MASKEQZ",
 		argLen: 2,
diff --git a/src/cmd/compile/internal/ssa/rewriteLOONG64.go b/src/cmd/compile/internal/ssa/rewriteLOONG64.go
index 1795ef68be..f4a5f788dc 100644
--- a/src/cmd/compile/internal/ssa/rewriteLOONG64.go
+++ b/src/cmd/compile/internal/ssa/rewriteLOONG64.go
@@ -88,6 +88,10 @@ func rewriteValueLOONG64(v *Value) bool {
 		return true
 	case OpAvg64u:
 		return rewriteValueLOONG64_OpAvg64u(v)
+	case OpBitLen32:
+		return rewriteValueLOONG64_OpBitLen32(v)
+	case OpBitLen64:
+		return rewriteValueLOONG64_OpBitLen64(v)
 	case OpClosureCall:
 		v.Op = OpLOONG64CALLclosure
 		return true
@@ -799,6 +803,44 @@ func rewriteValueLOONG64_OpAvg64u(v *Value) bool {
 		return true
 	}
 }
+func rewriteValueLOONG64_OpBitLen32(v *Value) bool {
+	v_0 := v.Args[0]
+	b := v.Block
+	// match: (BitLen32 <t> x)
+	// result: (NEGV <t> (SUBVconst <t> [32] (CLZW <t> x)))
+	for {
+		t := v.Type
+		x := v_0
+		v.reset(OpLOONG64NEGV)
+		v.Type = t
+		v0 := b.NewValue0(v.Pos, OpLOONG64SUBVconst, t)
+		v0.AuxInt = int64ToAuxInt(32)
+		v1 := b.NewValue0(v.Pos, OpLOONG64CLZW, t)
+		v1.AddArg(x)
+		v0.AddArg(v1)
+		v.AddArg(v0)
+		return true
+	}
+}
+func rewriteValueLOONG64_OpBitLen64(v *Value) bool {
+	v_0 := v.Args[0]
+	b := v.Block
+	// match: (BitLen64 <t> x)
+	// result: (NEGV <t> (SUBVconst <t> [64] (CLZV <t> x)))
+	for {
+		t := v.Type
+		x := v_0
+		v.reset(OpLOONG64NEGV)
+		v.Type = t
+		v0 := b.NewValue0(v.Pos, OpLOONG64SUBVconst, t)
+		v0.AuxInt = int64ToAuxInt(64)
+		v1 := b.NewValue0(v.Pos, OpLOONG64CLZV, t)
+		v1.AddArg(x)
+		v0.AddArg(v1)
+		v.AddArg(v0)
+		return true
+	}
+}
 func rewriteValueLOONG64_OpCom16(v *Value) bool {
 	v_0 := v.Args[0]
 	b := v.Block
@@ -4130,6 +4172,34 @@ func rewriteValueLOONG64_OpLOONG64ROTRV(v *Value) bool {
 func rewriteValueLOONG64_OpLOONG64SGT(v *Value) bool {
 	v_1 := v.Args[1]
 	v_0 := v.Args[0]
+	b := v.Block
+	typ := &b.Func.Config.Types
+	// match: (SGT (MOVVconst [c]) (NEGV (SUBVconst [d] x)))
+	// cond: is32Bit(d-c)
+	// result: (SGT x (MOVVconst [d-c]))
+	for {
+		if v_0.Op != OpLOONG64MOVVconst {
+			break
+		}
+		c := auxIntToInt64(v_0.AuxInt)
+		if v_1.Op != OpLOONG64NEGV {
+			break
+		}
+		v_1_0 := v_1.Args[0]
+		if v_1_0.Op != OpLOONG64SUBVconst {
+			break
+		}
+		d := auxIntToInt64(v_1_0.AuxInt)
+		x := v_1_0.Args[0]
+		if !(is32Bit(d - c)) {
+			break
+		}
+		v.reset(OpLOONG64SGT)
+		v0 := b.NewValue0(v.Pos, OpLOONG64MOVVconst, typ.UInt64)
+		v0.AuxInt = int64ToAuxInt(d - c)
+		v.AddArg2(x, v0)
+		return true
+	}
 	// match: (SGT (MOVVconst [c]) x)
 	// cond: is32Bit(c)
 	// result: (SGTconst [c] x)
@@ -4814,6 +4884,27 @@ func rewriteValueLOONG64_OpLOONG64SUBV(v *Value) bool {
 		v.AddArg(x)
 		return true
 	}
+	// match: (SUBV (MOVVconst [c]) (NEGV (SUBVconst [d] x)))
+	// result: (ADDVconst [c-d] x)
+	for {
+		if v_0.Op != OpLOONG64MOVVconst {
+			break
+		}
+		c := auxIntToInt64(v_0.AuxInt)
+		if v_1.Op != OpLOONG64NEGV {
+			break
+		}
+		v_1_0 := v_1.Args[0]
+		if v_1_0.Op != OpLOONG64SUBVconst {
+			break
+		}
+		d := auxIntToInt64(v_1_0.AuxInt)
+		x := v_1_0.Args[0]
+		v.reset(OpLOONG64ADDVconst)
+		v.AuxInt = int64ToAuxInt(c - d)
+		v.AddArg(x)
+		return true
+	}
 	return false
 }
 func rewriteValueLOONG64_OpLOONG64SUBVconst(v *Value) bool {
diff --git a/src/cmd/compile/internal/ssagen/ssa.go b/src/cmd/compile/internal/ssagen/ssa.go
index 548c2ad8fa..a4b0772fed 100644
--- a/src/cmd/compile/internal/ssagen/ssa.go
+++ b/src/cmd/compile/internal/ssagen/ssa.go
@@ -4545,12 +4545,12 @@ func InitTables() {
 		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
 			return s.newValue1(ssa.OpBitLen64, types.Types[types.TINT], args[0])
 		},
-		sys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)
+		sys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.Loong64, sys.MIPS, sys.PPC64, sys.Wasm)
 	addF("math/bits", "Len32",
 		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
 			return s.newValue1(ssa.OpBitLen32, types.Types[types.TINT], args[0])
 		},
-		sys.AMD64, sys.ARM64, sys.PPC64)
+		sys.AMD64, sys.ARM64, sys.Loong64, sys.PPC64)
 	addF("math/bits", "Len32",
 		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
 			if s.config.PtrSize == 4 {
@@ -4569,7 +4569,7 @@ func InitTables() {
 			x := s.newValue1(ssa.OpZeroExt16to64, types.Types[types.TUINT64], args[0])
 			return s.newValue1(ssa.OpBitLen64, types.Types[types.TINT], x)
 		},
-		sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)
+		sys.ARM64, sys.ARM, sys.S390X, sys.Loong64, sys.MIPS, sys.PPC64, sys.Wasm)
 	addF("math/bits", "Len16",
 		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
 			return s.newValue1(ssa.OpBitLen16, types.Types[types.TINT], args[0])
@@ -4584,7 +4584,7 @@ func InitTables() {
 			x := s.newValue1(ssa.OpZeroExt8to64, types.Types[types.TUINT64], args[0])
 			return s.newValue1(ssa.OpBitLen64, types.Types[types.TINT], x)
 		},
-		sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)
+		sys.ARM64, sys.ARM, sys.S390X, sys.Loong64, sys.MIPS, sys.PPC64, sys.Wasm)
 	addF("math/bits", "Len8",
 		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
 			return s.newValue1(ssa.OpBitLen8, types.Types[types.TINT], args[0])
@@ -4597,7 +4597,7 @@ func InitTables() {
 			}
 			return s.newValue1(ssa.OpBitLen64, types.Types[types.TINT], args[0])
 		},
-		sys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.MIPS, sys.PPC64, sys.Wasm)
+		sys.AMD64, sys.ARM64, sys.ARM, sys.S390X, sys.Loong64, sys.MIPS, sys.PPC64, sys.Wasm)
 	// LeadingZeros is handled because it trivially calls Len.
 	addF("math/bits", "Reverse64",
 		func(s *state, n *ir.CallExpr, args []*ssa.Value) *ssa.Value {
diff --git a/test/codegen/mathbits.go b/test/codegen/mathbits.go
index 90af677d6b..ca0fa3b938 100644
--- a/test/codegen/mathbits.go
+++ b/test/codegen/mathbits.go
@@ -17,6 +17,7 @@ func LeadingZeros(n uint) int {
 	// amd64/v3:"LZCNTQ", -"BSRQ"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV",-"SUB"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"CNTLZD"
@@ -29,6 +30,7 @@ func LeadingZeros64(n uint64) int {
 	// amd64/v3:"LZCNTQ", -"BSRQ"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV",-"SUB"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"CNTLZD"
@@ -41,6 +43,7 @@ func LeadingZeros32(n uint32) int {
 	// amd64/v3: "LZCNTL",- "BSRL"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZW"
+	// loong64:"CLZW",-"SUB"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"CNTLZW"
@@ -53,6 +56,7 @@ func LeadingZeros16(n uint16) int {
 	// amd64/v3: "LZCNTL",- "BSRL"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"CNTLZD"
@@ -65,6 +69,7 @@ func LeadingZeros8(n uint8) int {
 	// amd64/v3: "LZCNTL",- "BSRL"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"CNTLZD"
@@ -81,6 +86,7 @@ func Len(n uint) int {
 	// amd64/v3: "LZCNTQ"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"SUBC","CNTLZD"
@@ -93,6 +99,7 @@ func Len64(n uint64) int {
 	// amd64/v3: "LZCNTQ"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"SUBC","CNTLZD"
@@ -101,16 +108,23 @@ func Len64(n uint64) int {
 }
 
 func SubFromLen64(n uint64) int {
+	// loong64:"CLZV",-"ADD"
 	// ppc64le:"CNTLZD",-"SUBC"
 	// ppc64:"CNTLZD",-"SUBC"
 	return 64 - bits.Len64(n)
 }
 
+func CompareWithLen64(n uint64) bool {
+	// loong64:"CLZV",-"ADD",-"[$]64",-"[$]9"
+	return bits.Len64(n) < 9
+}
+
 func Len32(n uint32) int {
 	// amd64/v1,amd64/v2:"BSRQ","LEAQ",-"CMOVQEQ"
 	// amd64/v3: "LZCNTL"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZW"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64: "CNTLZW"
@@ -123,6 +137,7 @@ func Len16(n uint16) int {
 	// amd64/v3: "LZCNTL"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"SUBC","CNTLZD"
@@ -135,6 +150,7 @@ func Len8(n uint8) int {
 	// amd64/v3: "LZCNTL"
 	// s390x:"FLOGR"
 	// arm:"CLZ" arm64:"CLZ"
+	// loong64:"CLZV"
 	// mips:"CLZ"
 	// wasm:"I64Clz"
 	// ppc64le:"SUBC","CNTLZD"
-- 
2.40.0

